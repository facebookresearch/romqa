{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3f6e8f5-c502-46c6-a95d-ee73b2bd1cc1",
   "metadata": {},
   "source": [
    "# Fetching evidence\n",
    "\n",
    "As is the case in the original RoMQA experiments, we will create three versions of the data with different means of retrieving evidence.\n",
    "Here, the text corpus is taken to be the entire set of TREX documents.\n",
    "We will retrieve using three methods:\n",
    "\n",
    "1. We'll find gold evidence from database\n",
    "2. For the closed setting: we'll run BM25 document retrieval for each candidate entity, followed by DPR sentence retrieval using the question.\n",
    "3. For the open setting: we'll run BM25 document retrieval for the question, followed by DPR sentence retrieval again using the question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f76db55-249b-452e-a2b9-68ae83d181d8",
   "metadata": {},
   "source": [
    "## Gold evidence retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04fafe71-3b75-4580-bda5-e392f29aa3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import db_utils as D\n",
    "import bz2\n",
    "import ujson as json\n",
    "import sqlite3\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "fdb = 'annotations/data.db'\n",
    "db = sqlite3.connect(fdb, isolation_level=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a864dc8c-e8e9-4d84-8757-06de1e5229b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dev.json', 'rt') as f:\n",
    "    dev = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7144f8e7-db8d-43a7-90ac-2ee62144f2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_uri2id = {}\n",
    "prop_uri2id = {}\n",
    "\n",
    "for uri, i in db.execute('SELECT uri, id FROM ents'):\n",
    "    ent_uri2id[uri] = i\n",
    "    \n",
    "for uri, i in db.execute('SELECT uri, id FROM props'):\n",
    "    prop_uri2id[uri] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69e8c515-4cc8-4989-8b0e-b616cdbe2198",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_id2text = {}\n",
    "for i, text in db.execute('SELECT id, text FROM docs'):\n",
    "    docs_id2text[i] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98e8fcbd-880d-40ac-a02c-541f425f9f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Member of Dundee United F.C. born in Paisley. Not a citizen of Scotland\n",
      "{'uri': 'http://www.wikidata.org/entity/Q4545973', 'is_answer': False, 'text': 'George Gordon, Lord Haddo', 'aliases': [], 'desc': 'Scottish Freemason and the eldest son of George Gordon, 3rd Earl of Aberdeen'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'doc_id': 2015609,\n",
       "  'start': 0,\n",
       "  'end': 144,\n",
       "  'text': 'George Gordon, Lord Haddo (28 January 1764 – 2 October 1791) was a Scottish Freemason and the eldest son of George Gordon, 3rd Earl of Aberdeen.'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import functools\n",
    "\n",
    "\n",
    "@functools.lru_cache(maxsize=1024*1024)\n",
    "def retrieve_evidence_for_fact(ent, other_ent, prop, prop_dir):\n",
    "    if prop_dir == 'subj':\n",
    "        subj, obj = ent, other_ent\n",
    "    elif prop_dir == 'obj':\n",
    "        subj, obj = other_ent, ent\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    subj_id = ent_uri2id[subj]\n",
    "    obj_id = ent_uri2id[obj]\n",
    "    prop_id = prop_uri2id[prop]\n",
    "    match = {}\n",
    "    for doc_id, start, end in db.execute('SELECT E.doc_id, E.start, E.end FROM evidence E, trips T WHERE T.id=E.trip_id AND T.subj_id=? AND T.obj_id=? AND T.prop_id=?', (subj_id, obj_id, prop_id)):\n",
    "        text = docs_id2text[doc_id][start:end]\n",
    "        match[text] = dict(doc_id=doc_id, start=start, end=end)\n",
    "    lst = []\n",
    "    for k, v in match.items():\n",
    "        v['text'] = k\n",
    "        lst.append(v)\n",
    "    return lst\n",
    "    \n",
    "\n",
    "def retrieve_evidence_for_candidate(candidate, constraints):\n",
    "    evidence = []\n",
    "    for constraint in constraints:\n",
    "        evidence.extend(retrieve_evidence_for_fact(candidate['uri'], constraint['other_ent']['uri'], constraint['prop']['uri'], constraint['prop_dir']))\n",
    "    return evidence\n",
    "    \n",
    "    \n",
    "print(dev[0]['question'])\n",
    "print(dev[0]['candidates'][0])\n",
    "retrieve_evidence_for_candidate(dev[0]['candidates'][0], dev[0]['constraints'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8323ef9-fc4e-41f9-8d06-ed14e7d463a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p evidence/gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c695c289-f87d-4cf0-84b4-e9503e3a505c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a966c5f456d4370b0463294e3af1721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7068 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "dev_mapped = []\n",
    "for ex in tqdm(dev):\n",
    "    ex = copy.deepcopy(ex)\n",
    "    for c in ex['candidates']:\n",
    "        c['evidence'] = retrieve_evidence_for_candidate(c, ex['constraints'])\n",
    "    dev_mapped.append(ex)\n",
    "    \n",
    "with bz2.open('evidence/gold/dev.json.bz2', 'wt') as f:\n",
    "    json.dump(dev_mapped, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ce18dc7-26f1-40b0-a371-c8a135e2a01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3aa3a50f4b643daa7b1ef4698865f5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10649 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('test.noanswer.json', 'rt') as f:\n",
    "    test = json.load(f)\n",
    "\n",
    "test_mapped = []\n",
    "for ex in tqdm(test):\n",
    "    ex = copy.deepcopy(ex)\n",
    "    for c in ex['candidates']:\n",
    "        c['evidence'] = retrieve_evidence_for_candidate(c, ex['constraints'])\n",
    "    test_mapped.append(ex)\n",
    "    \n",
    "with bz2.open('evidence/gold/test.noanswer.json.bz2', 'wt') as f:\n",
    "    json.dump(test_mapped, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6682456d-267c-4d75-991b-ead51e56ba30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61734fa39a6b4ef2a47c2eb8cf444347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11260 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('train.json', 'rt') as f:\n",
    "    train = json.load(f)\n",
    "\n",
    "train_mapped = []\n",
    "for ex in tqdm(train):\n",
    "    ex = copy.deepcopy(ex)\n",
    "    for c in ex['candidates']:\n",
    "        c['evidence'] = retrieve_evidence_for_candidate(c, ex['constraints'])\n",
    "    train_mapped.append(ex)\n",
    "    \n",
    "with bz2.open('evidence/gold/train.json.bz2', 'wt') as f:\n",
    "    json.dump(train_mapped, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "00bbaf77-32d3-4e33-a18f-b73fce6cd6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'uri': 'http://www.wikidata.org/entity/Q4545973',\n",
       "  'is_answer': False,\n",
       "  'text': 'George Gordon, Lord Haddo',\n",
       "  'aliases': [],\n",
       "  'desc': 'Scottish Freemason and the eldest son of George Gordon, 3rd Earl of Aberdeen',\n",
       "  'evidence': [{'doc_id': 2015609,\n",
       "    'start': 0,\n",
       "    'end': 144,\n",
       "    'text': 'George Gordon, Lord Haddo (28 January 1764 – 2 October 1791) was a Scottish Freemason and the eldest son of George Gordon, 3rd Earl of Aberdeen.'}]},\n",
       " {'uri': 'http://www.wikidata.org/entity/Q3607690',\n",
       "  'is_answer': False,\n",
       "  'text': 'Alan Combe',\n",
       "  'aliases': [],\n",
       "  'desc': 'Scottish footballer',\n",
       "  'evidence': [{'doc_id': 1773034,\n",
       "    'start': 89,\n",
       "    'end': 193,\n",
       "    'text': 'Born in Edinburgh, Combe played for Cowdenbeath, St Mirren, Dundee United, Bradford City and Kilmarnock.'}]},\n",
       " {'uri': 'http://www.wikidata.org/entity/Q6223506',\n",
       "  'is_answer': False,\n",
       "  'text': 'John Brown',\n",
       "  'aliases': ['John Thomas Brown'],\n",
       "  'desc': 'Scottish footballer (1935-2000)',\n",
       "  'evidence': [{'doc_id': 3206815,\n",
       "    'start': 0,\n",
       "    'end': 149,\n",
       "    'text': 'John Brown (born 2 April 1935 in Edinburgh) is a Scottish former footballer, who played for Hibernian, Third Lanark, Tranmere and Hartlepools United.'}]},\n",
       " {'uri': 'http://www.wikidata.org/entity/Q3948331',\n",
       "  'is_answer': False,\n",
       "  'text': 'Sandy Archibald',\n",
       "  'aliases': [],\n",
       "  'desc': 'Scottish footballer and manager',\n",
       "  'evidence': [{'doc_id': 1884366,\n",
       "    'start': 0,\n",
       "    'end': 142,\n",
       "    'text': 'Alexander \"Sandy\" Archibald (23 November 1896 – 29 November 1946) was a Scottish footballer who played for Raith Rovers, Rangers and Scotland.'}]},\n",
       " {'uri': 'http://www.wikidata.org/entity/Q6183873',\n",
       "  'is_answer': False,\n",
       "  'text': 'Jerry Kerr',\n",
       "  'aliases': [],\n",
       "  'desc': 'Footballer (1912-1999)',\n",
       "  'evidence': [{'doc_id': 1518614,\n",
       "    'start': 307,\n",
       "    'end': 547,\n",
       "    'text': 'Persson was the first of five Scandinavian imports signed by Dundee United manager Jerry Kerr who was one of the first managers in Scotland to tap into the Scandinavian market to find talented and experienced players at an affordable price.'},\n",
       "   {'doc_id': 3188597,\n",
       "    'start': 0,\n",
       "    'end': 160,\n",
       "    'text': \"Jasper Jerald 'Jerry' Kerr (1 June 1912 – 8 November 1999) was a Scottish football player and manager, best known as manager of Dundee United from 1959 to 1971.\"}]}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_mapped[0]['candidates'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c5195f-ea1e-400e-b252-ab426d561627",
   "metadata": {},
   "source": [
    "## BM25 + DPR Retrieval\n",
    "\n",
    "First, build BM25 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7788902b-3d78-4441-87e3-3d6c70bb6cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b6704153604ebbbdb5937bc1a1d1b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizing docs:   0%|          | 0/3348807 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building bm25\n",
      "saving bm25\n"
     ]
    }
   ],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "import string\n",
    "import pickle\n",
    "from stop_words import STOP_WORDS\n",
    "\n",
    "\n",
    "def bm25_tokenizer(text):\n",
    "    tokenized_doc = []\n",
    "    for token in text.lower().split():\n",
    "        token = token.strip(string.punctuation)\n",
    "\n",
    "        if len(token) > 0 and token not in STOP_WORDS:\n",
    "            tokenized_doc.append(token)\n",
    "    return tokenized_doc\n",
    "\n",
    "\n",
    "# build a index\n",
    "fbm25 = 'evidence/bm25_index.pkl'\n",
    "sorted_docs = sorted(list(docs_id2text.items()), key=lambda tup: tup[0])\n",
    "\n",
    "\n",
    "if not os.path.isfile(fbm25):\n",
    "    tokenized_corpus = []\n",
    "    for i, text in tqdm(sorted_docs, 'tokenizing docs'):\n",
    "        tokenized_corpus.append(bm25_tokenizer(text))\n",
    "    print('building bm25')\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "    print('saving bm25')\n",
    "    with open(fbm25, 'wb') as f:\n",
    "        pickle.dump(bm25, f)\n",
    "    with bz2.open('evidence/sorted_docs.json.bz2', 'wt') as f:\n",
    "        json.dump(sorted_docs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8a4d08-da9e-41de-94fd-dd033aae4210",
   "metadata": {},
   "source": [
    "The remaining steps are fairly computationally involved and split into actual python scripts.\n",
    "\n",
    "Find top k documents for each entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a357fed-8e1d-44c3-87f5-81e6df255bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python bm25_retrieve.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9e6147c3-b93a-48df-a4a3-fdfbb1dc44f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9414734fac0f41d1997255cea053fcb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/605175 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "top_k = 5\n",
    "\n",
    "\n",
    "all_entities = set()\n",
    "for ex in train_mapped + dev_mapped + test_mapped:\n",
    "    for c in ex['candidates']:\n",
    "        all_entities.add(c['text'])\n",
    "        \n",
    "        \n",
    "all_entities = sorted(list(all_entities))\n",
    "ent2evidence = {}\n",
    "for ent in tqdm(all_entities):\n",
    "    scores = bm25.get_scores(bm25_tokenizer(ent))\n",
    "    top_k_inds = np.argpartition(scores, -top_k)[-top_k:]\n",
    "    out = []\n",
    "    for i in top_k_inds:\n",
    "        out.append(dict(score=scores[i], doc_index=i))\n",
    "    ent2evidence[ent] = out\n",
    "    \n",
    "with bz2.open('evidence/bm25_ent2evidence.json.bz2', 'wt') as f:\n",
    "    json.dump(ent2evidence, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ea288f-d3eb-4ab4-a126-05b7fa32cd10",
   "metadata": {},
   "source": [
    "Find top k documents for each question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daafc219-2bab-4e90-8e3b-d42e54a03275",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 5\n",
    "\n",
    "\n",
    "all_questions = set()\n",
    "for ex in train_mapped + dev_mapped + test_mapped:\n",
    "    all_questions.add(ex['question'])\n",
    "        \n",
    "        \n",
    "all_questions = sorted(list(all_questions))\n",
    "question2evidence = {}\n",
    "for question in tqdm(all_questions):\n",
    "    scores = bm25.get_scores(bm25_tokenizer(question))\n",
    "    top_k_inds = np.argpartition(bm25_scores, -top_k)[-top_k:]\n",
    "    out = []\n",
    "    for i in top_k_inds:\n",
    "        out.append(dict(score=scores[i], doc_index=i))\n",
    "    question2evidence[question] = out\n",
    "    \n",
    "with bz2.open('evidence/bm25_question2evidence.json.bz2', 'wt') as f:\n",
    "    json.dump(question2evidence, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0369a393-f24d-41fd-a935-dd150aa2afb7",
   "metadata": {},
   "source": [
    "For closed setting, for each question and each candidate, find top k sentences using DPR. This is fairly involved so we'll do this in an actual python script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd136c2-e59e-47f1-97a6-de5bcb61ada3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python dpr_retrieve.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0866fb-2673-4f36-bcec-bbdbae8c6d28",
   "metadata": {},
   "source": [
    "For open setting, for each question, find top k sentences using DPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9755825b-2189-4f84-806a-528bdba49957",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python dpr_retrieve_open.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
